---
title: "Generative Models"
author: "Bakro"
date: "1/17/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Generative_models

```{r}
set.seed(430)
iris_obs = nrow(iris)
iris_idx = sample(iris_obs, size = trunc(0.50 * iris_obs))
# iris_index = sample(iris_obs, size = trunc(0.10 * iris_obs))
iris_trn = iris[iris_idx, ]
iris_tst = iris[-iris_idx, ]
```

```{r}
caret::featurePlot(x = iris_trn[, c("Sepal.Length", "Sepal.Width", 
                                    "Petal.Length", "Petal.Width")], 
                   y = iris_trn$Species,
                   plot = "density", 
                   scales = list(x = list(relation = "free"), 
                                 y = list(relation = "free")), 
                   adjust = 1.5, 
                   pch = "|", 
                   layout = c(2, 2), 
                   auto.key = list(columns = 3))
```

```{r}
caret::featurePlot(x = iris_trn[, c("Sepal.Length", "Sepal.Width", 
                                    "Petal.Length", "Petal.Width")], 
                   y = iris_trn$Species,
                   plot = "ellipse",
                   auto.key = list(columns = 3))
```

```{r}
caret::featurePlot(x = iris_trn[, c("Sepal.Length", "Sepal.Width", 
                                    "Petal.Length", "Petal.Width")], 
                   y = iris_trn$Species,
                   plot = "box",
                   scales = list(y = list(relation = "free"),
                                 x = list(rot = 90)),
                   layout = c(4, 1))
```

## Linear Discriminant Analysis

LDA assumes that the predictors are multivariate normal conditioned on the classes.

$X \mid Y = k \sim N(\mu_k, \Sigma)$

$$
f_k({\mathbf x}) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}\exp\left[-\frac{1}{2}(\mathbf x - \mu_k)^{\prime}\Sigma^{-1}(\mathbf x - \mu_k)\right]
$$

Notice that Σ does **not** depend on k, that is, we are assuming the same Σ for each class. We then use information from all the classes to estimate Σ.

To fit an LDA model, we use the `lda()` function from the `MASS` package.

```{r}
library(MASS)
iris_lda = lda(Species ~ ., data = iris_trn)
iris_lda
```

```{r}
iris_lda_trn_pred = predict(iris_lda, iris_trn)$class
iris_lda_tst_pred = predict(iris_lda, iris_tst)$class
```

```{r}
calc_class_err = function(actual, predicted) {
  mean(actual != predicted)
}

calc_class_err(predicted = iris_lda_trn_pred, actual = iris_trn$Species)

calc_class_err(predicted = iris_lda_tst_pred, actual = iris_tst$Species)

table(predicted = iris_lda_tst_pred, actual = iris_tst$Species)
```

```{r}
iris_lda_flat = lda(Species ~ ., data = iris_trn, prior = c(1, 1, 1) / 3)
iris_lda_flat

iris_lda_flat_trn_pred = predict(iris_lda_flat, iris_trn)$class
iris_lda_flat_tst_pred = predict(iris_lda_flat, iris_tst)$class

calc_class_err(predicted = iris_lda_flat_trn_pred, actual = iris_trn$Species)

calc_class_err(predicted = iris_lda_flat_tst_pred, actual = iris_tst$Species)
# This actually gives a better test accuracy!
```

## Quadratic Discriminant Analysis

QDA also assumes that the predictors are multivariate normal conditioned on the classes.

$X \mid Y = k \sim N(\mu_k, \Sigma_k)$

$f_k({\mathbf x}) = \frac{1}{(2\pi)^{p/2}|\Sigma_k|^{1/2}}\exp\left[-\frac{1}{2}(\mathbf x - \mu_k)^{\prime}\Sigma_{k}^{-1}(\mathbf x - \mu_k)\right]$

Notice that now ΣkΣk **does** depend on kk, that is, we are allowing a different ΣkΣk for each class. We only use information from class kk to estimate ΣkΣk.

```{r}
iris_qda = qda(Species ~ ., data = iris_trn)
iris_qda

iris_qda_trn_pred = predict(iris_qda, iris_trn)$class
iris_qda_tst_pred = predict(iris_qda, iris_tst)$class

calc_class_err(predicted = iris_qda_trn_pred, actual = iris_trn$Species)
calc_class_err(predicted = iris_qda_tst_pred, actual = iris_tst$Species)

table(predicted = iris_qda_tst_pred, actual = iris_tst$Species)
```

## Naive Bayes

```{r}
library(e1071)
iris_nb = naiveBayes(Species ~ ., data = iris_trn)
iris_nb
head(predict(iris_nb, iris_trn))

head(predict(iris_nb, iris_trn, type = "class"))
head(predict(iris_nb, iris_trn, type = "raw"))

iris_nb_trn_pred = predict(iris_nb, iris_trn)
iris_nb_tst_pred = predict(iris_nb, iris_tst)

calc_class_err(predicted = iris_nb_trn_pred, actual = iris_trn$Species)
calc_class_err(predicted = iris_nb_tst_pred, actual = iris_tst$Species)
                           
table(predicted = iris_nb_tst_pred, actual = iris_tst$Species)
```

| **Method**      | **Train Error** | **Test Error** |
|-----------------|-----------------|----------------|
| LDA             | 0.0266667       | 0.0133333      |
| LDA, Flat Prior | 0.0266667       | 0.0133333      |
| QDA             | 0.0133333       | 0.0533333      |
| Naive Bayes     | 0.0533333       | 0.0266667      |

# Resampling

```{r}
gen_sim_data = function(sample_size) {
  x = runif(n = sample_size, min = -1, max = 1)
  y = rnorm(n = sample_size, mean = x ^ 3, sd = 0.25)
  data.frame(x, y)
}

set.seed(42)
sim_data = gen_sim_data(sample_size = 200)
sim_idx  = sample(1:nrow(sim_data), 160)
sim_trn  = sim_data[sim_idx, ]
sim_val  = sim_data[-sim_idx, ]
```

```{r}
plot(y ~ x, data = sim_trn, col = "dodgerblue", pch = 20)
grid()
curve(x ^ 3, add = TRUE, col = "black", lwd = 2)
```

```{r}
calc_rmse = function(actual, predicted) {
  sqrt(mean((actual - predicted) ^ 2))
}
```

```{r}
fit = lm(y ~ poly(x, 10), data = sim_trn)
calc_rmse(actual = sim_trn$y, predicted = predict(fit, sim_trn))
calc_rmse(actual = sim_val$y, predicted = predict(fit, sim_val))
```

## Validation-Set Approach

```{r}
num_sims = 100
num_degrees = 10
val_rmse = matrix(0, ncol = num_degrees, nrow = num_sims)
```

```{r}
set.seed(42)
for (i in 1:num_sims) {
  # simulate data
  sim_data = gen_sim_data(sample_size = 200)
  # set aside validation set
  sim_idx = sample(1:nrow(sim_data), 160)
  sim_trn = sim_data[sim_idx, ]
  sim_val = sim_data[-sim_idx, ]
  # fit models and store RMSEs
  for (j in 1:num_degrees) {
    #fit model
    fit = glm(y ~ poly(x, degree = j), data = sim_trn)
    # calculate error
    val_rmse[i, j] = calc_rmse(actual = sim_val$y, predicted = predict(fit, sim_val))
  }
}
```

![](C:/Users/mjd/AppData/Local/RStudio/tmp/paste-6898F5D6.png)

## Cross-Validation

```{r}
glm_fit = glm(y ~ poly(x, 3), data = sim_trn)
coef(glm_fit)
```

```{r}
lm_fit  = lm(y ~ poly(x, 3), data = sim_trn)
coef(lm_fit)
```

```{r}
sqrt(boot::cv.glm(sim_trn, glm_fit)$delta)
```

```{r}
sqrt(boot::cv.glm(sim_trn, glm_fit, K = 5)$delta)
```

We repeat the above simulation study, this time performing 5-fold cross-validation. With a total sample size of n=200n=200 each validation set has 40 observations, as did the single validation set in the previous simulations

```{r}
cv_rmse = matrix(0, ncol = num_degrees, nrow = num_sims)
```

```{r}
set.seed(42)
for (i in 1:num_sims) {
  # simulate data, use all data for training
  sim_trn = gen_sim_data(sample_size = 200)
  # fit models and store RMSE
  for (j in 1:num_degrees) {
    #fit model
    fit = glm(y ~ poly(x, degree = j), data = sim_trn)
    # calculate error
    cv_rmse[i, j] = sqrt(boot::cv.glm(sim_trn, fit, K = 5)$delta[1])
  }
}
```

## Test Data

```{r}
calc_err = function(actual, predicted) {
  mean(actual != predicted)
}

set.seed(42)
n = 200
p = 10000
x = replicate(p, rnorm(n))
y = c(rbinom(n = n, size = 1, prob = 0.5))
full_data = data.frame(y, x)

trn_idx  = sample(1:nrow(full_data), trunc(nrow(full_data) * 0.5))
trn_data = full_data[trn_idx,   ]
tst_data = full_data[-trn_idx, ]
```

```{r}
correlations = apply(trn_data[, -1], 2, cor, y = trn_data$y)
```

```{r}
selected = order(abs(correlations), decreasing = TRUE)[1:25]
correlations[selected]
```

```{r}
trn_screen = trn_data[c(1, selected)]
tst_screen = tst_data[c(1, selected)]
```

```{r}
add_log_mod = glm(y ~ ., data = trn_screen, family = "binomial")
boot::cv.glm(trn_screen, add_log_mod, K = 10)$delta[1]
```

```{r}
add_log_pred = (predict(add_log_mod, newdata = tst_screen, type = "response") > 0.5) * 1
calc_err(predicted = add_log_pred, actual = tst_screen$y)
```

```{r}
caret::createFolds(trn_data$y, k = 10)
```

```{r}
# use the caret package to obtain 10 "folds"
folds = caret::createFolds(trn_data$y, k = 10)

# for each fold
# - pre-screen variables on the 9 training folds
# - fit model to these variables
# - get error on validation fold
fold_err = rep(0, length(folds))

for (i in seq_along(folds)) {

  # split for fold i  
  trn_fold = trn_data[-folds[[i]], ]
  val_fold = trn_data[folds[[i]], ]

  # screening for fold i  
  correlations = apply(trn_fold[, -1], 2, cor, y = trn_fold[,1])
  selected = order(abs(correlations), decreasing = TRUE)[1:25]
  trn_fold_screen = trn_fold[ , c(1, selected)]
  val_fold_screen = val_fold[ , c(1, selected)]

  # error for fold i  
  add_log_mod = glm(y ~ ., data = trn_fold_screen, family = "binomial")
  add_log_prob = predict(add_log_mod, newdata = val_fold_screen, type = "response")
  add_log_pred = ifelse(add_log_prob > 0.5, yes = 1, no = 0)
  fold_err[i] = mean(add_log_pred != val_fold_screen$y)
  
}

```

```{r}
fold_err
mean(fold_err)
```

## Bootstrap
